{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "import ylearn\n",
    "from ylearn.causal_discovery import CausalDiscovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/data/train.csv')\n",
    "test = pd.read_csv('./dataset/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan\n",
    "def build_data(train):\n",
    "    train_ = {}\n",
    "    for i in train.columns:\n",
    "        train_i = train[i]\n",
    "        if any(train[i].isna()):\n",
    "            train_i = train_i.replace(np.nan, train[i].mean())\n",
    "        if len(train_i.value_counts()) <= 20 and train_i.dtype != object:\n",
    "            train_i = train_i.astype(int)\n",
    "        train_[i] = train_i\n",
    "\n",
    "    return pd.DataFrame(train_)\n",
    "\n",
    "train = build_data(train)\n",
    "test = build_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cov = list(train.columns)\n",
    "# save data and their corresponding transformers\n",
    "class TransData:\n",
    "    def __init__(self, name, is_obj=False):\n",
    "        self.is_obj = is_obj\n",
    "        self.name = name\n",
    "        self.transformer = None\n",
    "\n",
    "    def __call__(self, data):\n",
    "        self.df = data[self.name]\n",
    "        series = self.df.to_numpy().reshape(-1, 1)\n",
    "        if self.df.dtype == object:\n",
    "            self.is_obj = True\n",
    "            self.transformer = OrdinalEncoder()\n",
    "            self.data = self.transformer.fit_transform(series).astype(int)\n",
    "        elif self.df.dtype != int:\n",
    "            self.transformer = StandardScaler()\n",
    "            self.data = self.transformer.fit_transform(series)\n",
    "        else:\n",
    "            self.data = series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "data_dict = {}\n",
    "cat_name = []\n",
    "test_dict = {}\n",
    "\n",
    "for name in all_cov:\n",
    "    t = TransData(name=name)\n",
    "    t(train)\n",
    "    data_dict[name] = t.data.reshape(-1, )\n",
    "    if t.is_obj:\n",
    "        cat_name.append(name)\n",
    "    if name not in ['treatment', 'outcome']:\n",
    "        try:\n",
    "            test_i = t.transformer.transform(test[name].values.reshape(-1, 1)).reshape(-1, )\n",
    "        except:\n",
    "            test_i = test[name]\n",
    "        test_dict[name] = test_i\n",
    "train_transformed = pd.DataFrame(data_dict)\n",
    "test_data = pd.DataFrame(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_0</th>\n",
       "      <th>V_1</th>\n",
       "      <th>V_2</th>\n",
       "      <th>V_3</th>\n",
       "      <th>V_4</th>\n",
       "      <th>V_5</th>\n",
       "      <th>V_6</th>\n",
       "      <th>V_7</th>\n",
       "      <th>V_8</th>\n",
       "      <th>V_9</th>\n",
       "      <th>...</th>\n",
       "      <th>V_32</th>\n",
       "      <th>V_33</th>\n",
       "      <th>V_34</th>\n",
       "      <th>V_35</th>\n",
       "      <th>V_36</th>\n",
       "      <th>V_37</th>\n",
       "      <th>V_38</th>\n",
       "      <th>V_39</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.723577</td>\n",
       "      <td>-0.305753</td>\n",
       "      <td>-0.713223</td>\n",
       "      <td>-1.621706</td>\n",
       "      <td>-0.110603</td>\n",
       "      <td>0</td>\n",
       "      <td>1.967215</td>\n",
       "      <td>-1.605903</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>1.170614</td>\n",
       "      <td>-0.043524</td>\n",
       "      <td>1.491432</td>\n",
       "      <td>53</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.620006</td>\n",
       "      <td>1.144513</td>\n",
       "      <td>-0.713223</td>\n",
       "      <td>-0.836881</td>\n",
       "      <td>-0.329293</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.321160</td>\n",
       "      <td>0.287543</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935753</td>\n",
       "      <td>0.229336</td>\n",
       "      <td>0.849727</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.110879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.844489</td>\n",
       "      <td>0.105237</td>\n",
       "      <td>1.239680</td>\n",
       "      <td>-1.558425</td>\n",
       "      <td>-0.300993</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.277983</td>\n",
       "      <td>0.717924</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.043339</td>\n",
       "      <td>-0.713962</td>\n",
       "      <td>-0.861334</td>\n",
       "      <td>0.631476</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.258860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218723</td>\n",
       "      <td>-0.367827</td>\n",
       "      <td>-0.713223</td>\n",
       "      <td>-1.575069</td>\n",
       "      <td>-0.870663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952558</td>\n",
       "      <td>0.775616</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358267</td>\n",
       "      <td>0.035055</td>\n",
       "      <td>0.845040</td>\n",
       "      <td>0.112702</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.267371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183640</td>\n",
       "      <td>0.928402</td>\n",
       "      <td>-0.713223</td>\n",
       "      <td>-0.134138</td>\n",
       "      <td>0.654154</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.472279</td>\n",
       "      <td>0.776770</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078760</td>\n",
       "      <td>-0.046988</td>\n",
       "      <td>-0.110786</td>\n",
       "      <td>0.682046</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.166405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        V_0       V_1       V_2       V_3       V_4  V_5       V_6       V_7  \\\n",
       "0  1.723577 -0.305753 -0.713223 -1.621706 -0.110603    0  1.967215 -1.605903   \n",
       "1 -0.620006  1.144513 -0.713223 -0.836881 -0.329293    0 -0.321160  0.287543   \n",
       "2 -0.844489  0.105237  1.239680 -1.558425 -0.300993    1 -0.277983  0.717924   \n",
       "3  0.218723 -0.367827 -0.713223 -1.575069 -0.870663    1  0.952558  0.775616   \n",
       "4  0.183640  0.928402 -0.713223 -0.134138  0.654154    1 -0.472279  0.776770   \n",
       "\n",
       "   V_8  V_9  ...      V_32      V_33      V_34      V_35  V_36  V_37  V_38  \\\n",
       "0    0    3  ...  0.983957  1.170614 -0.043524  1.491432    53    -2     0   \n",
       "1    0  999  ...  0.935753  0.229336  0.849727  0.005753    50     0     2   \n",
       "2    0  999  ... -2.043339 -0.713962 -0.861334  0.631476    37     1     1   \n",
       "3    0  999  ... -0.358267  0.035055  0.845040  0.112702    35     1     0   \n",
       "4    0  999  ... -0.078760 -0.046988 -0.110786  0.682046    58     1     0   \n",
       "\n",
       "   V_39  treatment   outcome  \n",
       "0     3          2  0.965484  \n",
       "1     4          0  1.110879  \n",
       "2     2          2 -2.258860  \n",
       "3     3          0 -0.267371  \n",
       "4     2          2 -0.166405  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find relations between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = train_transformed.drop(['treatment', 'outcome'], axis=1).values\n",
    "x = train_transformed['treatment'].values\n",
    "y = train_transformed['outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_model = RandomForestClassifier(n_estimators=150, criterion='entropy', max_features=0.5, max_depth=50)\n",
    "y_model = RandomForestRegressor(n_estimators=150, max_features=0.5, max_depth=100, )\n",
    "x_model.fit(V, x)\n",
    "x_importance = x_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model_input = np.concatenate((V, x.reshape(-1, 1)), axis=1)\n",
    "y_model.fit(y_model_input, y=y)\n",
    "y_importance = y_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounder_list = []\n",
    "for i, (x_, y_) in enumerate(zip(x_importance, y_importance)):\n",
    "    if x_ >= 1e-3 and y_ >= 1e-5:\n",
    "        confounder_list.append(all_cov[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_new = train_transformed[confounder_list + ['treatment'] + ['outcome']]\n",
    "# V_new = train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TLearner(model=RandomForestRegressor(max_features=0.6, n_estimators=150), kwargs=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ylearn.estimator_model import TLearner, XLearner\n",
    "tl1 = TLearner(model=RandomForestRegressor(n_estimators=150, max_features=0.6),)\n",
    "tl2 = TLearner(model=RandomForestRegressor(n_estimators=150, max_features=0.6))\n",
    "tl1.fit(data=V_new, treatment='treatment', outcome='outcome', treat=1, control=0, covariate=confounder_list)\n",
    "tl2.fit(data=V_new, treatment='treatment', outcome='outcome', treat=2, control=0, covariate=confounder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ce(data, x1_model, x2_model):\n",
    "    ce1 = x1_model.estimate(data)\n",
    "    ce2 = x2_model.estimate(data)\n",
    "    return np.concatenate([ce1.reshape(-1, 1), ce2.reshape(-1, 1)], axis=1)\n",
    "ce = get_ce(V_new, tl1, tl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ce`是训练集（train.csv）上的因果效应，另外需要估计测试集（test.csv）上的因果效应`ce_test`。最后需要把`ce_test`拼接在`ce`之后，存储到一个csv文件中上传到平台取得得分。得分为一个数值，越小说明结果越接近真实值，得分最小值为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_test = get_ce(test_data, x1_model=tl1, x2_model=tl2)\n",
    "ce = np.concatenate((ce, ce_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ylearn.estimator_model import DML4CATE\n",
    "\n",
    "dml = DML4CATE(cf_fold=1, x_model=RandomForestClassifier(n_estimators=250, criterion=\"entropy\", max_depth=150, min_samples_leaf=2, min_samples_split=3, max_features=3),\n",
    "               y_model=RandomForestRegressor(n_estimators=250, max_depth=150, min_samples_leaf=2, min_samples_split=2, max_features=3), is_discrete_treatment=True)\n",
    "dml.fit(data=V_new, outcome='outcome', treatment='treatment', covariate=confounder_list,)\n",
    "ce_dml = dml.effect_nji(data=V_new, control=0)\n",
    "ce_dml_test = dml.effect_nji(data=test_data, control=0)\n",
    "ce_dml_train = ce_dml[:, :, 1:].reshape(-1, 2)\n",
    "ce_dml_all = np.concatenate([ce_dml_train, ce_dml_test[:, :, 1:].reshape(-1, 2)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalTree(max_depth=100, max_features=20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ylearn.estimator_model import CausalTree\n",
    "\n",
    "ct1 = CausalTree(max_depth=100, min_samples_split=2, max_features=20)\n",
    "ct2 = CausalTree(max_depth=100, max_features=20)\n",
    "ct1.fit(data=V_new, outcome='outcome', treatment='treatment', covariate=confounder_list, treat=[1], control=[0])\n",
    "ct2.fit(data=V_new, outcome='outcome', treatment='treatment', covariate=confounder_list, treat=[2], control=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_ct = get_ce(V_new, ct1, ct2)\n",
    "ce_ct_test = get_ce(test_data, ct1, ct2)\n",
    "ce_ct_all = np.concatenate([ce_ct, ce_ct_test], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ylearn_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8581d1eecfa97f28a0c41513ba1ff519bf462b808573b2f3a58298c51aea96c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
